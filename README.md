# RL Agent Comparisons using Diambra Arena

A reinforcement learning project using the DIAMBRA Arena to train and evaluate agents in fighting games. The repository is structured into two main sections: the **final project**, and **experimental scripts** used during research and prototyping. A single shared virtual environment is used for both.

---

## ğŸ—‚ Project Structure

```
rl-agents-comparison-diambra/
â”‚
â”œâ”€â”€ final_project/               # Final project training and evaluation
â”‚   â”œâ”€â”€ train_agent.py
â”‚   â””â”€â”€ play_agent.py
â”‚
â”œâ”€â”€ experiments/                # Experimental code and sandbox testing
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ ray-rllib-train.py
â”‚
â”œâ”€â”€ results/                    # Logs and metrics
â”œâ”€â”€ exported_policy/            # Trained models or agents (excluded from Git)
â”œâ”€â”€ checkpoints/                # Model checkpoints (excluded from Git)
â”œâ”€â”€ Roms/                       # Game ROMs (excluded from Git)
â”‚
â”œâ”€â”€ venv/                       # Shared virtual environment (excluded from Git)
â”œâ”€â”€ requirements.txt            # Shared dependencies
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## Setup (Python version 3.9)

```bash
# Clone the repo
git clone https://github.com/Soncity2/rl-agents-comparison-diambra.git
cd rl-agents-comparison-diambra

# Create and activate virtual environment
python3.9 -m venv venv
source venv/bin/activate

# Install all required dependencies
pip install --upgrade pip
pip install -r requirements.txt
```

---

### *Add the tektagt.zip ROM file to the rom directory.
ROM file instructions: https://docs.diambra.ai/envs/games/tektagt/

### *Install Docker Desktop 
https://www.docker.com/products/docker-desktop/

---

## ğŸ§ª Run Experiments

These are experimental scripts used to test features and train with RLlib.

```bash
diambra run -r **Roms Directory path** python basic_examples/main.py              # DIAMBRA Arena integration test
diambra run -r **Roms Directory path** python basic_examples/ray-rllib-train.py   # Training via Ray RLlib
```

---

## ğŸ“ Final Project

This is the main logic for training and evaluating the final agent.

```bash
diambra run -r **Roms Directory path** python final_project/train_agent.py --algo ppo --iters 10 --save --export-policy     # Train the final model
diambra run -r **Roms Directory path** python final_project/play_agent.py      # Run a trained model
```

---

### ğŸ§¾ Command Line Options

The training and evaluation scripts accept the following command-line arguments:

| Argument                 | Type     | Default     | Choices                   | Description                                                                 |
|--------------------------|----------|-------------|---------------------------|-----------------------------------------------------------------------------|
| `--algo`                 | `str`    | `"ppo"`     | `ppo`, `dqn`, `rainbow`   | Select the RL algorithm to use for training.                               |
| `--iters`                | `int`    | `10`        | _Any positive integer_    | Number of training iterations.                                             |
| `--play`                 | `flag`   | `False`     | â€”                         | If set, runs the agent in play mode after training.                        |
| `--save`                 | `flag`   | `False`     | â€”                         | If set, saves the trained agent as a checkpoint.                           |
| `--load-checkpoint`      | `str`    | `None`      | _File path_               | Loads an agent from a specified checkpoint path.                           |
| `--load-latest`          | `flag`   | `False`     | â€”                         | Automatically loads the latest checkpoint for the selected algorithm.      |
| `--export-policy`        | `flag`   | `False`     | â€”                         | Exports the trained policy model for inference use after training/loading. |

---

## ğŸ“Š Results

Training logs and performance metrics are saved as CSV files in the `results/` directory. You can visualize and compare various RL algorithms from here.

---

## ğŸ“ Notes

- Game ROMs are not included for licensing reasons. Add your own under the `Roms/` folder.
- The `venv/`, `checkpoints/`, and other large or sensitive files are excluded via `.gitignore`.

---

## ğŸ“œ License

[MIT License](LICENSE)
